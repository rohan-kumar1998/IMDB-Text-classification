{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMDB RNN model .ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "JF1lcmfIQerq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "a36b2620-654a-4ccc-b22b-ec63ed69db97"
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch\n",
        "\n",
        "!pip install https://github.com/pytorch/text/archive/master.zip"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting https://github.com/pytorch/text/archive/master.zip\n",
            "  Downloading https://github.com/pytorch/text/archive/master.zip\n",
            "\u001b[K     \\ 921kB 19.4MB/s\n",
            "Requirement already satisfied (use --upgrade to upgrade): torchtext==0.4.0 from https://github.com/pytorch/text/archive/master.zip in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4.0) (4.28.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4.0) (2.18.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4.0) (0.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4.0) (1.14.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4.0) (1.11.0)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4.0) (2.6)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4.0) (1.22)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4.0) (2018.11.29)\n",
            "Building wheels for collected packages: torchtext\n",
            "  Running setup.py bdist_wheel for torchtext ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-6sde3hjw/wheels/5a/86/3d/30ae7dfdfeb1748bb11b3da173fb9634141fbb39e9e9847317\n",
            "Successfully built torchtext\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NXQTtbOXQf_P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "98cbd80f-01e2-4fb7-81ab-c120b5c46b20"
      },
      "cell_type": "code",
      "source": [
        "!pip install https://github.com/pytorch/text/archive/master.zip"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting https://github.com/pytorch/text/archive/master.zip\n",
            "  Downloading https://github.com/pytorch/text/archive/master.zip\n",
            "\u001b[K     \\ 880kB 20.0MB/s\n",
            "Requirement already satisfied (use --upgrade to upgrade): torchtext==0.4.0 from https://github.com/pytorch/text/archive/master.zip in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4.0) (4.28.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4.0) (2.18.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4.0) (0.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4.0) (1.14.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4.0) (1.11.0)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4.0) (2.6)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4.0) (1.22)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4.0) (2018.11.29)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4.0) (3.0.4)\n",
            "Building wheels for collected packages: torchtext\n",
            "  Running setup.py bdist_wheel for torchtext ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-ulx3tocs/wheels/5a/86/3d/30ae7dfdfeb1748bb11b3da173fb9634141fbb39e9e9847317\n",
            "Successfully built torchtext\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "__3dZurXQb_S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn \n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import torchvision.datasets as dsets \n",
        "import torchvision.transforms as transforms\n",
        "import torchtext \n",
        "from torchtext import datasets \n",
        "from torchtext import data\n",
        "from gensim.models import KeyedVectors\n",
        "import gensim\n",
        "import nltk\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MWY6kxPvQb_d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "SEED = 1234\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "TEXT = data.Field(tokenize='spacy')\n",
        "LABEL = data.LabelField(dtype=torch.float)\n",
        "\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n",
        "\n",
        "train_data, valid_data = train_data.split(random_state=random.seed(SEED))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hr7yHUO_RO22",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b1997adf-d187-46e3-908f-27f1d8ccb657"
      },
      "cell_type": "code",
      "source": [
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GhTSSDydQb_i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "outputId": "7939e7df-6d11-44ed-a02b-cfba2e942b40"
      },
      "cell_type": "code",
      "source": [
        "TEXT.build_vocab(train_data, max_size=25000, vectors=\"glove.6B.300d\")\n",
        "LABEL.build_vocab(train_data)\n",
        "dir(TEXT)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getstate__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__setstate__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " 'batch_first',\n",
              " 'build_vocab',\n",
              " 'dtype',\n",
              " 'dtypes',\n",
              " 'eos_token',\n",
              " 'fix_length',\n",
              " 'ignore',\n",
              " 'include_lengths',\n",
              " 'init_token',\n",
              " 'is_target',\n",
              " 'lower',\n",
              " 'numericalize',\n",
              " 'pad',\n",
              " 'pad_first',\n",
              " 'pad_token',\n",
              " 'postprocessing',\n",
              " 'preprocess',\n",
              " 'preprocessing',\n",
              " 'process',\n",
              " 'sequential',\n",
              " 'stop_words',\n",
              " 'tokenize',\n",
              " 'tokenizer_args',\n",
              " 'truncate_first',\n",
              " 'unk_token',\n",
              " 'use_vocab',\n",
              " 'vocab',\n",
              " 'vocab_cls']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "metadata": {
        "id": "D_UDDUE3Qb_r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits((train_data, valid_data, test_data), batch_size=BATCH_SIZE, device=device)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5T2BADGlQb_w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "8cf6f603-15f0-4259-91cb-2e3ac1177a16"
      },
      "cell_type": "code",
      "source": [
        "for batch in train_iterator:\n",
        "    print(dir(batch))\n",
        "    print(batch.fields)\n",
        "    break"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_get_field_values', 'batch_size', 'dataset', 'fields', 'fromvars', 'input_fields', 'label', 'target_fields', 'text']\n",
            "dict_keys(['text', 'label'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "n_GcazZeQb_0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class lstmclassifier(nn.Module):\n",
        "    def __init__(self,input_dim, vocab_size, hidden_dim, output_dim, embedding_dim):\n",
        "        super(lstmclassifier, self).__init__() \n",
        "        self.hidden_dim = hidden_dim \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
        "        self.linear = nn.Linear(hidden_dim, output_dim)\n",
        "    def forward(self, x):\n",
        "        x = x.permute(1,0)\n",
        "        x = self.embedding(x)\n",
        "        #print(x.shape)  #(batch_size, sequence_length, input_length)\n",
        "        x = x.permute(1,0,2) #(seq_len, batch_size, input_dim)\n",
        "        if torch.cuda.is_available():\n",
        "          h0 = Variable(torch.zeros(1, x.size(1), self.hidden_dim).cuda())\n",
        "        else:\n",
        "          h0 = Variable(torch.zeros(1, x.size(1), self.hidden_dim))\n",
        "        if torch.cuda.is_available():\n",
        "          c0 = Variable(torch.zeros(1,x.size(1), self.hidden_dim).cuda())\n",
        "        else:\n",
        "          c0 = Variable(torch.zeros(1,x.size(1), self.hidden_dim)) \n",
        "        out,(hn,cn) = self.lstm(x,(h0,c0))\n",
        "        #print(out.shape)\n",
        "        #final_output = self.linear(out[-1])\n",
        "        final_output = F.relu(self.linear(out[-1]))\n",
        "        #print(out[-1].shape)\n",
        "        return final_output\n",
        "        #final_output = self.linear(h0[-1])\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k35xrXT3Qb_5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "b1f88760-6f29-45b3-f15b-8fbe8070fc5d"
      },
      "cell_type": "code",
      "source": [
        "input_dim = len(TEXT.vocab)\n",
        "hidden_dim = 128 \n",
        "output_dim = 1 \n",
        "embedding_dim = 300 \n",
        "vocab_size = input_dim\n",
        "\n",
        "model = lstmclassifier(input_dim , vocab_size, hidden_dim, output_dim, embedding_dim)\n",
        "if torch.cuda.is_available():\n",
        "  model.cuda()\n",
        "optimizer = torch.optim.Adadelta(model.parameters())\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "\n",
        "model.embedding.weight.data.copy_(pretrained_embeddings)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0466,  0.2132, -0.0074,  ...,  0.0091, -0.2099,  0.0539],\n",
              "        ...,\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.1957,  0.5752, -0.1345,  ..., -0.2973,  0.1073, -0.5232]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "metadata": {
        "id": "SBLX3-MBQb__",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum()/len(correct)\n",
        "    return acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yDCJRe8xQcAG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        predictions = model(batch.text).squeeze(1)\n",
        "        \n",
        "        loss = criterion(predictions, batch.label)\n",
        "        \n",
        "        acc = binary_accuracy(predictions, batch.label)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qD_bUKPPQcAO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            predictions = model(batch.text).squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, batch.label)\n",
        "            \n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XcCKFELpm50j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "baf75314-f26e-4d24-bb05-5c0d3f69fa8c"
      },
      "cell_type": "code",
      "source": [
        "N_EPOCHS = 5\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Val. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}% |')"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Epoch: 01 | Train Loss: 0.693 | Train Acc: 49.64% | Val. Loss: 0.693 | Val. Acc: 50.79% |\n",
            "| Epoch: 02 | Train Loss: 0.693 | Train Acc: 49.67% | Val. Loss: 0.693 | Val. Acc: 50.79% |\n",
            "| Epoch: 03 | Train Loss: 0.693 | Train Acc: 49.67% | Val. Loss: 0.693 | Val. Acc: 50.79% |\n",
            "| Epoch: 04 | Train Loss: 0.693 | Train Acc: 49.67% | Val. Loss: 0.693 | Val. Acc: 50.79% |\n",
            "| Epoch: 05 | Train Loss: 0.693 | Train Acc: 49.67% | Val. Loss: 0.693 | Val. Acc: 50.79% |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5vnD83pim7_6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}